{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01f74fb6",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "465d33dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`xtol` termination condition is satisfied.\n",
      "Number of iterations: 53, function evaluations: 276, CG iterations: 67, optimality: 7.19e-08, constraint violation: 1.11e-16, execution time: 0.074 s.\n",
      "x1 = -0.7674418547974058\n",
      "x2 = 0.2558139515991352\n",
      "x3 = 0.6279069813539099\n",
      "x4 = -0.11627907815563937\n",
      "x5 = 0.2558139515991352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  warn('delta_grad == 0.0. Check if the approximated '\n"
     ]
    }
   ],
   "source": [
    "# MAE 598 - Design Optimization HW1 Problem 1\n",
    "# Benjamin Webb\n",
    "# 8/27/2022\n",
    "\n",
    "import scipy.optimize as sp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def Fx(x):\n",
    "\t# Function to minimize in problem 1\n",
    "\t# x is a 5 element array\n",
    "\tF = (x[0] - x[1]) ** 2 + (x[1] + x[2] - 2) ** 2 + (x[3] - 1) ** 2 + (x[4] - 1) ** 2\n",
    "\n",
    "\treturn F\n",
    "\n",
    "\n",
    "# Main program for problem 1\n",
    "if __name__ == '__main__':\n",
    "\t# HW1 Problem 1\n",
    "\n",
    "\t# Define Constraints\n",
    "\t# Bound constraints\n",
    "\tbound_constraints = sp.Bounds([-10.0, -10.0, -10.0, -10.0, -10.0], [10.0, 10.0, 10.0, 10.0, 10.0])\n",
    "\n",
    "\t# Linear constraints\n",
    "\tA = np.array([[1.0, 3.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 1.0, -2.0], [0.0, 1.0, 0.0, 0.0, -1.0]])\n",
    "\tlb = np.array([0.0, 0.0, 0.0])\n",
    "\tub = np.array([0.0, 0.0, 0.0])\n",
    "\tlinear_constraints = sp.LinearConstraint(A, lb, ub)\n",
    "\n",
    "\t# Define initial guess\n",
    "\tx0 = np.array([-1.0, 0.0, 1.0, 0.0, 0.0])\n",
    "\n",
    "\t# Solve minimization problem\n",
    "\tmin_sol = sp.minimize(Fx, x0, method='trust-constr', bounds=bound_constraints, constraints=linear_constraints, options={'verbose': 1})\n",
    "\n",
    "\tprint('x1 = ' + str(min_sol.x[0]))\n",
    "\tprint('x2 = ' + str(min_sol.x[1]))\n",
    "\tprint('x3 = ' + str(min_sol.x[2]))\n",
    "\tprint('x4 = ' + str(min_sol.x[3]))\n",
    "\tprint('x5 = ' + str(min_sol.x[4]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cff701",
   "metadata": {},
   "source": [
    "I first set my initial guess to **x0** = 0. With this guess, it took the solver 48 iterations to solve this problem. I next tried setting **x0** = -10, and the solver took 58 iterations. With **x0** = 10, the solver took 60 iterations. I then tried **x0** = [-1, 0, 1, 0, 0], since these are the closest whole numbers to the actual solution. This required 53 iterations to solve.\n",
    "\n",
    "Interestingly, the initial guess of **x0** = 0 required the least iterations. I would have assumed that the **x0** closest to the actual solution would require the fewest iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7edce76",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d7a424",
   "metadata": {},
   "source": [
    "$\\mathrm{f(x)=b^{T}x+x^{T}Ax\\;\\;x,b\\,\\mathit{\\in}\\,\\mathbb{R}^{n}\\;\\;A\\,\\mathit{\\in}\\,\\mathbb{R}^{nxn}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd29f9e7",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae46835",
   "metadata": {},
   "source": [
    "**gradient:**\n",
    "\n",
    "$\\mathrm{\\nabla_{x}\\left(\\begin{bmatrix}b_{1} & b_{2} & \\cdots & b_{n}\\end{bmatrix}\\begin{bmatrix}x_{1}\\\\\n",
    "x_{2}\\\\\n",
    "\\vdots\\\\\n",
    "x_{n}\n",
    "\\end{bmatrix}+\\begin{bmatrix}x_{1} & x_{2} & \\cdots & x_{n}\\end{bmatrix}\\begin{bmatrix}A_{11} & A_{12} & \\cdots & A_{1n}\\\\\n",
    "A_{21} & \\ddots &  & \\vdots\\\\\n",
    "\\vdots &  & \\ddots & \\vdots\\\\\n",
    "A_{n1} & \\cdots & \\cdots & A_{nn}\n",
    "\\end{bmatrix}\\begin{bmatrix}x_{1}\\\\\n",
    "x_{2}\\\\\n",
    "\\vdots\\\\\n",
    "x_{n}\n",
    "\\end{bmatrix}\\right)}$\n",
    "\n",
    "$\\mathrm{\\Longrightarrow\\nabla_{x}\\left(\\begin{bmatrix}b_{1} & b_{2} & \\cdots & b_{n}\\end{bmatrix}\\begin{bmatrix}x_{1}\\\\\n",
    "x_{2}\\\\\n",
    "\\vdots\\\\\n",
    "x_{n}\n",
    "\\end{bmatrix}\\right)=\\begin{bmatrix}b_{1}\\\\\n",
    "b_{2}\\\\\n",
    "\\vdots\\\\\n",
    "b_{n}\n",
    "\\end{bmatrix}}$\n",
    "\n",
    "\\begin{multline*}\n",
    "\\mathrm{\\Longrightarrow\\nabla_{x}\\left(\\begin{bmatrix}x_{1} & x_{2} & \\cdots & x_{n}\\end{bmatrix}\\begin{bmatrix}A_{11} & A_{12} & \\cdots & A_{1n}\\\\\n",
    "A_{21} & \\ddots &  & \\vdots\\\\\n",
    "\\vdots &  & \\ddots & \\vdots\\\\\n",
    "A_{n1} & \\cdots & \\cdots & A_{nn}\n",
    "\\end{bmatrix}\\begin{bmatrix}x_{1}\\\\\n",
    "x_{2}\\\\\n",
    "\\vdots\\\\\n",
    "x_{n}\n",
    "\\end{bmatrix}\\right)\\Longrightarrow}\\\\\n",
    "\\mathrm{\\nabla_{x}\\left(\\begin{bmatrix}A_{11}x_{1}+A_{21}x_{2}+\\ldots+A_{n1}x_{n} & A_{12}x_{1}+A_{22}x_{2}+\\ldots+A_{n2}x_{n} & \\cdots & A_{1n}x_{1}+A_{2n}x_{2}+\\ldots+A_{nn}x_{n}\\end{bmatrix}\\begin{bmatrix}x_{1}\\\\\n",
    "x_{2}\\\\\n",
    "\\vdots\\\\\n",
    "x_{n}\n",
    "\\end{bmatrix}\\right)}\n",
    "\\end{multline*}\n",
    "\n",
    "$\\mathrm{\\Downarrow}$\n",
    "\n",
    "$\\mathrm{\\Longrightarrow\\nabla_{x}f(x)=\\begin{bmatrix}b_{1}\\\\\n",
    "b_{2}\\\\\n",
    "\\vdots\\\\\n",
    "b_{n}\n",
    "\\end{bmatrix}+\\begin{bmatrix}2A_{11}x_{1}+\\sum_{j\\neq i,i}^n A_{ij}x_{j} & 2A_{22}+\\sum_{j\\neq i,i}^n Aijx_{j} & \\cdots & 2A_{nn}+\\sum_{j\\neq i,i}^n A_{ij}x_{j}\\end{bmatrix}^{T}}$\n",
    "\n",
    "**Hessian:**\n",
    "\n",
    "$\\mathrm{H(x)=\\frac{d^{2}f}{dx^{2}}=\\frac{d}{dx}\\left(\\frac{df}{dx}\\right)=\\frac{d}{dx}\\left(\\nabla_{x}f(x)\\right)}$\n",
    "\n",
    "$\\mathrm{\\Longrightarrow\\frac{d}{dx}\\left(\\begin{bmatrix}b_{1}\\\\\n",
    "b_{2}\\\\\n",
    "\\vdots\\\\\n",
    "b_{n}\n",
    "\\end{bmatrix}\\right)=0}$\n",
    "\n",
    "$\\mathrm{\\Longrightarrow\\frac{d}{dx}\\left(\\begin{bmatrix}2A_{11}x_{1}+\\sum_{j\\neq i,i}^n A_{ij}x_{j} & 2A_{22}+\\sum_{j\\neq i,i}^n A_{ij}x_{j} & \\cdots & 2A_{nn}+\\sum_{j\\neq i,i}^n A_{ij}x_{j}\\end{bmatrix}^{T}\\right)=\\begin{bmatrix}2A_{11}+0+\\ldots+0 & 2A_{22}+0+\\ldots+0 & \\cdots & 2A_{nn}+0+\\ldots+0\\end{bmatrix}^{T}}$\n",
    "\n",
    "The derivative w/r to $\\mathrm{x_{i}}$ is zero for the summation terms since $\\mathrm{j\\neq i}$\n",
    "\n",
    "$\\mathrm{\\Downarrow}$\n",
    "\n",
    "$\\mathrm{H(x)=\\frac{d^{2}f}{dx^{2}}=\\begin{bmatrix}2A_{11} & 0 & \\cdots & 0\\\\\n",
    "0 & 2A_{22} & \\cdots & 0\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "0 & 0 & \\cdots & 2A_{nn}\n",
    "\\end{bmatrix}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa9d982",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01ed373",
   "metadata": {},
   "source": [
    "**1st-Order:**  \n",
    "$\\mathrm{f(x)\\approx f(x_{0})+\\left.\\frac{df}{dx}\\right|_{x_{0}}^{T}\\left(x-x_{0}\\right)\\Rightarrow f(x_{0})+\\left.\\nabla_{x}f(x)\\right|_{x_{0}}^{T}\\left(x-x_{0}\\right)}$\n",
    "\n",
    "**2nd-Order:**  \n",
    "$\\mathrm{f(x)\\approx f(x_{0})+\\left.\\frac{df}{dx}\\right|_{x_{0}}^{T}\\left(x-x_{0}\\right)+\\frac{\\left(x-x_{0}\\right)^{T}}{2}\\left.\\frac{d^{2}f}{dx^{2}}\\right|_{x_{0}}(x-x_{0})\\Rightarrow f(x_{0})+\\left.\\nabla_{x}f(x)\\right|_{x_{0}}^{T}\\left(x-x_{0}\\right)+\\frac{\\left(x-x_{0}\\right)^{T}}{2}\\left.H(x)\\right|_{x_{0}}(x-x_{0})}$\n",
    "\n",
    "Evaluating these at x = 0, gives,\n",
    "\n",
    "$\\mathrm{f(0)\\approx f(x_{0})+\\left.\\nabla_{x}f(0)\\right|_{x_{0}}^{T}\\left(0-x_{0}\\right)}$\n",
    "\n",
    "$\\mathrm{f(0)\\approx f(x_{0})+\\left.\\nabla_{x}f(0)\\right|_{x_{0}}^{T}\\left(0-x_{0}\\right)+\\frac{\\left(0-x_{0}\\right)^{T}}{2}\\left.H(0)\\right|_{x_{0}}(0-x_{0})}$\n",
    "\n",
    "Using the gradient and Hessian from part a, these become,\n",
    "\n",
    "**1st-Order:**  \n",
    "$\\mathrm{f(0)\\approx f(x_{0})-\\begin{bmatrix}b_{1} & b_{2} & \\cdots & b_{n}\\end{bmatrix}\\begin{bmatrix}x_{0}\\\\\n",
    "x_{0}\\\\\n",
    "\\vdots\\\\\n",
    "x_{0}\n",
    "\\end{bmatrix}-\\begin{bmatrix}2A_{11}x_{1}+\\sum_{j\\neq i,i}^n A_{ij}x_{j} & 2A_{22}+\\sum_{j\\neq i,i}^n A_{ij}x_{j} & \\cdots & 2A_{nn}+\\sum_{j\\neq i,i}^n A_{ij}x_{j}\\end{bmatrix}\\begin{bmatrix}x_{0}\\\\\n",
    "x_{0}\\\\\n",
    "\\vdots\\\\\n",
    "x_{0}\n",
    "\\end{bmatrix}}$\n",
    "\n",
    "**2nd-Order:**  \n",
    "\\begin{multline*}\n",
    "\\mathrm{f(0)\\approx f(x_{0})-\\begin{bmatrix}b_{1} & b_{2} & \\cdots & b_{n}\\end{bmatrix}\\begin{bmatrix}x_{0}\\\\\n",
    "x_{0}\\\\\n",
    "\\vdots\\\\\n",
    "x_{0}\n",
    "\\end{bmatrix}-\\begin{bmatrix}2A_{11}x_{1}+\\sum_{j\\neq i,i}^n A_{ij}x_{j} & 2A_{22}+\\sum_{j\\neq i,i}^n A_{ij}x_{j} & \\cdots & 2A_{nn}+\\sum_{j\\neq i,i}^n A_{ij}x_{j}\\end{bmatrix}\\begin{bmatrix}x_{0}\\\\\n",
    "x_{0}\\\\\n",
    "\\vdots\\\\\n",
    "x_{0}\n",
    "\\end{bmatrix}}\\\\\n",
    "\\mathrm{+\\frac{1}{2}\\begin{bmatrix}x_{0} & x_{0} & \\cdots & x_{0}\\end{bmatrix}\\begin{bmatrix}2A_{11} & 0 & \\cdots & 0\\\\\n",
    "0 & 2A_{22} & \\cdots & 0\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "0 & 0 & \\cdots & 2A_{nn}\n",
    "\\end{bmatrix}\\begin{bmatrix}x_{0}\\\\\n",
    "x_{0}\\\\\n",
    "\\vdots\\\\\n",
    "x_{0}\n",
    "\\end{bmatrix}}\n",
    "\\end{multline*}\n",
    "\n",
    "The 1st-order approximation **is not** going to be exact because $\\mathrm{f(x)}$ is not a linear function, it is quadratic. Therefore, the 1st-order approximation will be neglecting the 2nd-order terms of $\\mathrm{f(x)}$. For this same reason, the 2nd-order approximation **will be** exact since we are modeling a 2nd-order function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4619a11f",
   "metadata": {},
   "source": [
    "### c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13106e7",
   "metadata": {},
   "source": [
    "Since A is symmetric matrix, it will be positive definite if all of its eigenvalues are positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3d3904",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
